{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision.transforms import Compose, ToPILImage, Resize, ToTensor, Normalize\n",
    "import torchvision.transforms as transforms\n",
    "# from torchvision.transforms import RandomResizedCrop, RandomHorizontalFlip, RandomVerticalFlip, RandomAffine, RandomErasing, GaussianBlur\n",
    "\n",
    "import timm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config / Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'resnet50.ra_in1k'\n",
    "# TRIAL_NAME = f'250314_{MODEL_NAME}_5fold'\n",
    "TRIAL_NAME = f'250421_{MODEL_NAME}_5fold_10xEpoch_seed1'\n",
    "TRAINING = True\n",
    "\n",
    "N_EPOCHS = 10000\n",
    "BATCH_SIZE = 80\n",
    "LR = 3e-4\n",
    "N_FOLDS = 5\n",
    "SEED = 1\n",
    "STOP_THRESHOLD = 500\n",
    "IN_MEMORY_MODELS = False\n",
    "BEST_ACC = False\n",
    "ES_COOLDOWN = 200 # N_EPOCHS//5\n",
    "CLASSES = 10\n",
    "ENSEMBLE='sv'\n",
    "TTA = True\n",
    "VAL_TTA = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed)  \n",
    "    np.random.seed(seed) \n",
    "    torch.manual_seed(seed) \n",
    "    torch.cuda.manual_seed(seed) \n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False  \n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar-10 Auto Augmentation values and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShearX(object):\n",
    "    def __init__(self, fillcolor=(128)):\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    def __call__(self, x, magnitude):\n",
    "        return x.transform(\n",
    "            x.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n",
    "            Image.BICUBIC, fillcolor=self.fillcolor)\n",
    "\n",
    "\n",
    "class ShearY(object):\n",
    "    def __init__(self, fillcolor=(128)):\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    def __call__(self, x, magnitude):\n",
    "        return x.transform(\n",
    "            x.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n",
    "            Image.BICUBIC, fillcolor=self.fillcolor)\n",
    "\n",
    "\n",
    "class TranslateX(object):\n",
    "    def __init__(self, fillcolor=(128)):\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    def __call__(self, x, magnitude):\n",
    "        return x.transform(\n",
    "            x.size, Image.AFFINE, (1, 0, magnitude * x.size[0] * random.choice([-1, 1]), 0, 1, 0),\n",
    "            fillcolor=self.fillcolor)\n",
    "\n",
    "\n",
    "class TranslateY(object):\n",
    "    def __init__(self, fillcolor=(128)):\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    def __call__(self, x, magnitude):\n",
    "        return x.transform(\n",
    "            x.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * x.size[1] * random.choice([-1, 1])),\n",
    "            fillcolor=self.fillcolor)\n",
    "\n",
    "\n",
    "class Rotate(object):\n",
    "    # from https://stackoverflow.com/questions/\n",
    "    # 5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n",
    "    def __call__(self, x, magnitude):\n",
    "        rot = x.convert(\"RGBA\").rotate(magnitude * random.choice([-1, 1]))\n",
    "        return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(x.mode)\n",
    "\n",
    "\n",
    "class Color(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageEnhance.Color(x).enhance(1 + magnitude * random.choice([-1, 1]))\n",
    "\n",
    "\n",
    "class Posterize(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.posterize(x, magnitude)\n",
    "\n",
    "\n",
    "class Solarize(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.solarize(x, magnitude)\n",
    "\n",
    "\n",
    "class Contrast(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageEnhance.Contrast(x).enhance(1 + magnitude * random.choice([-1, 1]))\n",
    "\n",
    "\n",
    "class Sharpness(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageEnhance.Sharpness(x).enhance(1 + magnitude * random.choice([-1, 1]))\n",
    "\n",
    "\n",
    "class Brightness(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageEnhance.Brightness(x).enhance(1 + magnitude * random.choice([-1, 1]))\n",
    "\n",
    "\n",
    "class AutoContrast(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.autocontrast(x)\n",
    "\n",
    "\n",
    "class Equalize(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.equalize(x)\n",
    "\n",
    "\n",
    "class Invert(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.invert(x)\n",
    "\n",
    "class SubPolicy(object):\n",
    "    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128)):\n",
    "        ranges = {\n",
    "            \"shearX\": np.linspace(0, 0.3, 10),\n",
    "            \"shearY\": np.linspace(0, 0.3, 10),\n",
    "            \"translateX\": np.linspace(0, 150 / 331, 10),\n",
    "            \"translateY\": np.linspace(0, 150 / 331, 10),\n",
    "            \"rotate\": np.linspace(0, 30, 10),\n",
    "            \"color\": np.linspace(0.0, 0.9, 10),\n",
    "            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int_),\n",
    "            \"solarize\": np.linspace(256, 0, 10),\n",
    "            \"contrast\": np.linspace(0.0, 0.9, 10),\n",
    "            \"sharpness\": np.linspace(0.0, 0.9, 10),\n",
    "            \"brightness\": np.linspace(0.0, 0.9, 10),\n",
    "            \"autocontrast\": [0] * 10,\n",
    "            \"equalize\": [0] * 10,\n",
    "            \"invert\": [0] * 10\n",
    "        }\n",
    "\n",
    "        func = {\n",
    "            \"shearX\": ShearX(fillcolor=fillcolor),\n",
    "            \"shearY\": ShearY(fillcolor=fillcolor),\n",
    "            \"translateX\": TranslateX(fillcolor=fillcolor),\n",
    "            \"translateY\": TranslateY(fillcolor=fillcolor),\n",
    "            \"rotate\": Rotate(),\n",
    "            \"color\": Color(),\n",
    "            \"posterize\": Posterize(),\n",
    "            \"solarize\": Solarize(),\n",
    "            \"contrast\": Contrast(),\n",
    "            \"sharpness\": Sharpness(),\n",
    "            \"brightness\": Brightness(),\n",
    "            \"autocontrast\": AutoContrast(),\n",
    "            \"equalize\": Equalize(),\n",
    "            \"invert\": Invert()\n",
    "        }\n",
    "\n",
    "        self.p1 = p1\n",
    "        self.operation1 = func[operation1]\n",
    "        self.magnitude1 = ranges[operation1][magnitude_idx1]\n",
    "        self.p2 = p2\n",
    "        self.operation2 = func[operation2]\n",
    "        self.magnitude2 = ranges[operation2][magnitude_idx2]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p1:\n",
    "            img = self.operation1(img, self.magnitude1)\n",
    "        if random.random() < self.p2:\n",
    "            img = self.operation2(img, self.magnitude2)\n",
    "        return img\n",
    "\n",
    "class CIFAR10Policy(object):\n",
    "    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n",
    "\n",
    "        Example:\n",
    "        >>> policy = CIFAR10Policy()\n",
    "        >>> transformed = policy(image)\n",
    "\n",
    "        Example as a PyTorch Transform:\n",
    "        >>> transform=transforms.Compose([\n",
    "        >>>     transforms.Resize(256),\n",
    "        >>>     CIFAR10Policy(),\n",
    "        >>>     transforms.ToTensor()])\n",
    "    \"\"\"\n",
    "    def __init__(self, fillcolor=(128)):\n",
    "        self.policies = [\n",
    "            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n",
    "            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n",
    "            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n",
    "            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n",
    "            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n",
    "\n",
    "            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n",
    "            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n",
    "            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n",
    "            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n",
    "            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n",
    "\n",
    "            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n",
    "            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n",
    "            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n",
    "            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n",
    "            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n",
    "\n",
    "            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n",
    "            SubPolicy(0.2, \"equalize\", 8, 0.6, \"equalize\", 4, fillcolor),\n",
    "            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n",
    "            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n",
    "            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n",
    "\n",
    "            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n",
    "            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n",
    "            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n",
    "            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n",
    "            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n",
    "        ]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        policy_idx = random.randint(0, len(self.policies) - 1)\n",
    "        return self.policies[policy_idx](img)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"AutoAugment CIFAR10 Policy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train['label'] = encoder.fit_transform(train['label'])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets & DataLoaders & criterion setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, pixel_df, label_df=None, transform=None):\n",
    "        self.pixel_df = pixel_df.reset_index(drop=True)\n",
    "        self.label_df = label_df.reset_index(drop=True) if label_df is not None else None\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pixel_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Reshape to (32, 32) from flattened data\n",
    "        image = self.pixel_df.iloc[idx].values.astype(np.uint8).reshape(32, 32)\n",
    "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # shape: (1, 32, 32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.label_df is not None:\n",
    "            label = torch.tensor(self.label_df.iloc[idx], dtype=torch.long)\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "# RandomResizedCrop((224,224), scale=(0.8, 1)),\n",
    "# transforms.RandomAffine(\n",
    "#     degrees=(-180, 180),\n",
    "#     translate=(0.4, 0.4),\n",
    "#     scale=(0.8, 1.2),\n",
    "#     shear=(-20, 20)\n",
    "# ),\n",
    "\n",
    "train_transform = Compose([\n",
    "    ToPILImage(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    CIFAR10Policy(),\n",
    "    ToTensor(),\n",
    "    Cutout(n_holes=1, length=16),\n",
    "    Normalize(mean = [0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "test_transform = Compose([\n",
    "    ToPILImage(),\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean = [0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "if TTA:\n",
    "    tta_transforms = [\n",
    "        transforms.Compose([transforms.RandomHorizontalFlip(p=1.0)]),\n",
    "        transforms.Compose([transforms.RandomVerticalFlip(p=1.0)]),\n",
    "        transforms.Compose([transforms.RandomRotation((0, 30))]),\n",
    "    ]\n",
    "\n",
    "loader_params = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': 8,\n",
    "    'pin_memory': True\n",
    "}\n",
    "\n",
    "test_loader_params = {\n",
    "    'batch_size': 1,\n",
    "    'num_workers': 8,\n",
    "    'pin_memory': True\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training / Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "def validate_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            if VAL_TTA:\n",
    "                tta_images = [tta_transform(images) for tta_transform in tta_transforms]\n",
    "                tta_outputs = [model(tta_image) for tta_image in tta_images]\n",
    "                outputs = [outputs] + tta_outputs\n",
    "                outputs = torch.stack(outputs).mean(dim=0)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "def hv_validate_one_epoch(models, loader, criterion, device):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            sf_outputs = torch.zeros((images.size(0), CLASSES)).to(device)\n",
    "            outputs = torch.zeros((images.size(0), CLASSES)).to(device)\n",
    "            for model in models:\n",
    "                output = model(images)\n",
    "\n",
    "                if TTA:\n",
    "                    tta_images = [tta_transform(images) for tta_transform in tta_transforms]\n",
    "                    tta_outputs = [model(tta_image) for tta_image in tta_images]\n",
    "                    output = [output] + tta_outputs\n",
    "                    output = torch.stack(output).mean(dim=0)\n",
    "\n",
    "                # soft-voting\n",
    "                sf_outputs = sf_outputs + output\n",
    "\n",
    "                # hard-voting\n",
    "                _, predict_indices = torch.max(output.data, dim=1)\n",
    "                pred_one_hot = torch.zeros((images.shape[0], CLASSES)).to(device)\n",
    "                pred_one_hot.scatter_(1, predict_indices.unsqueeze(1), 1)\n",
    "                outputs = outputs + pred_one_hot\n",
    "\n",
    "            max_val, _ = torch.max(outputs, dim=1, keepdim=True)\n",
    "            cnt = torch.sum(outputs == max_val, dim=1)\n",
    "            for i in range(cnt.shape[0]):\n",
    "                if cnt[i] > 1:\n",
    "                    output[i] = sf_outputs[i]\n",
    "            outputs = outputs / len(models)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "def sv_validate_one_epoch(models, loader, criterion, device):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = torch.zeros((images.size(0), CLASSES)).to(device)\n",
    "            for model in models:\n",
    "                output = model(images)\n",
    "\n",
    "                if TTA:\n",
    "                    tta_images = [tta_transform(images) for tta_transform in tta_transforms]\n",
    "                    tta_outputs = [model(tta_image) for tta_image in tta_images]\n",
    "                    output = [output] + tta_outputs\n",
    "                    output = torch.stack(output).mean(dim=0)\n",
    "\n",
    "                outputs = outputs + output\n",
    "            outputs = outputs / len(models)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1218/10000] Train Loss: 0.0491 | Val Loss: 0.2264 | Val Accuracy: 95.4545% | Best Accuracy: 99.3506% | Best loss: 0.0227 | 500/500 ES\n",
      "0th-fold model Acc: 99.3506%, Loss: 0.022699884767946484\n",
      "Epoch [1888/10000] Train Loss: 0.0226 | Val Loss: 0.1364 | Val Accuracy: 98.0519% | Best Accuracy: 100.0000% | Best loss: 0.0058 | 500/500 ESS\n",
      "1th-fold model Acc: 100.0000%, Loss: 0.005849817035985845\n",
      "Epoch [2456/10000] Train Loss: 0.0346 | Val Loss: 0.0620 | Val Accuracy: 98.7013% | Best Accuracy: 99.3506% | Best loss: 0.0118 | 500/500 ES\n",
      "2th-fold model Acc: 99.3506%, Loss: 0.011825455872753224\n",
      "Epoch [2903/10000] Train Loss: 0.0446 | Val Loss: 0.3717 | Val Accuracy: 95.4545% | Best Accuracy: 98.0519% | Best loss: 0.1062 | 500/500 ES\n",
      "3th-fold model Acc: 98.0519%, Loss: 0.10618829039377523\n",
      "Epoch [1184/10000] Train Loss: 0.0591 | Val Loss: 0.1997 | Val Accuracy: 98.0392% | Best Accuracy: 98.0392% | Best loss: 0.0487 | 500/500 ES\n",
      "4th-fold model Acc: 98.0392%, Loss: 0.0486677436316325\n"
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    models = []\n",
    "\n",
    "    for i, (train_idx, valid_idx) in enumerate(skf.split(train.iloc[:, 2:], train['label'])):\n",
    "        train_dataset = CustomDataset(pixel_df=train.iloc[train_idx, 2:], label_df=train.iloc[train_idx, 1], transform=train_transform)\n",
    "        valid_dataset = CustomDataset(pixel_df=train.iloc[valid_idx, 2:], label_df=train.iloc[valid_idx, 1], transform=test_transform)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, shuffle=True, **loader_params)\n",
    "        valid_loader = DataLoader(valid_dataset, shuffle=False, **loader_params)\n",
    "\n",
    "        model = timm.create_model(\n",
    "            model_name=MODEL_NAME,\n",
    "            pretrained=False,\n",
    "            num_classes=CLASSES,\n",
    "            in_chans=1\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        best_acc = 0.0\n",
    "        best_model = None\n",
    "        \n",
    "        stop_count = 0\n",
    "\n",
    "        for epoch in range(N_EPOCHS):\n",
    "            train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            val_loss, val_acc = validate_one_epoch(model, valid_loader, criterion, device)\n",
    "            \n",
    "            if BEST_ACC:\n",
    "                print(f\"\\rEpoch [{epoch+1}/{N_EPOCHS}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Accuracy: {val_acc*100:.4f}% | Best Accuracy: {best_acc*100:.4f}% | Best loss: {best_loss:.4f} | {stop_count}/{STOP_THRESHOLD} ES\", end='')\n",
    "                if val_acc > best_acc:\n",
    "                    best_acc = val_acc\n",
    "                    best_loss = val_loss\n",
    "                    best_model = model\n",
    "                    stop_count = 0\n",
    "                    torch.save(best_model.state_dict(), f'./{TRIAL_NAME}_{i}_model_weight.pth')\n",
    "            else:\n",
    "                print(f\"\\rEpoch [{epoch+1}/{N_EPOCHS}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Accuracy: {val_acc*100:.4f}% | Best Accuracy: {best_acc*100:.4f}% | Best loss: {best_loss:.4f} | {stop_count}/{STOP_THRESHOLD} ES\", end='')\n",
    "                if val_loss < best_loss:\n",
    "                    best_acc = val_acc\n",
    "                    best_loss = val_loss\n",
    "                    best_model = model\n",
    "                    stop_count = 0\n",
    "                    torch.save(best_model.state_dict(), f'./{TRIAL_NAME}_{i}_model_weight.pth')\n",
    "        \n",
    "            if epoch > ES_COOLDOWN and stop_count >= STOP_THRESHOLD:\n",
    "                break\n",
    "\n",
    "            if type(scheduler) == optim.lr_scheduler.ReduceLROnPlateau:\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "            if epoch > ES_COOLDOWN:\n",
    "                stop_count += 1\n",
    "\n",
    "        if IN_MEMORY_MODELS:\n",
    "            models.append(best_model)\n",
    "        \n",
    "        print(f'\\n{i}th-fold model Acc: {best_acc*100:.4f}%, Loss: {best_loss}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SV model's Test Loss: 0.0000 | Test Accuracy: 100.0000%\n"
     ]
    }
   ],
   "source": [
    "if ENSEMBLE == 'sv':\n",
    "    models = []\n",
    "    for i in range(N_FOLDS):\n",
    "        model_state_dict = torch.load(f'./{TRIAL_NAME}_{i}_model_weight.pth',)\n",
    "        model = timm.create_model(\n",
    "            model_name=MODEL_NAME,\n",
    "            pretrained=False,\n",
    "            num_classes=CLASSES,\n",
    "            in_chans=1\n",
    "        ).to(device)\n",
    "        model.load_state_dict(model_state_dict)\n",
    "        models.append(model)\n",
    "\n",
    "    total_dataset = CustomDataset(pixel_df=train.iloc[: , 2:], label_df=train.iloc[: , 1], transform=test_transform)\n",
    "    total_loader = DataLoader(total_dataset, shuffle=True, **loader_params)\n",
    "\n",
    "    total_loss, total_acc = sv_validate_one_epoch(models, total_loader, criterion, device)\n",
    "    print(f\"SV model's Test Loss: {total_loss:.4f} | Test Accuracy: {total_acc*100:.4f}%\")\n",
    "\n",
    "    test_dataset = CustomDataset(pixel_df=test.iloc[:, 1:], transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=False, **test_loader_params)\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = torch.zeros((images.size(0), CLASSES)).to(device)\n",
    "            for model in models:\n",
    "                output = model(images)\n",
    "\n",
    "                if TTA:\n",
    "                    tta_images = [tta_transform(images) for tta_transform in tta_transforms]\n",
    "                    tta_outputs = [model(tta_image) for tta_image in tta_images]\n",
    "                    output = [output] + tta_outputs\n",
    "                    output = torch.stack(output).mean(dim=0)\n",
    "\n",
    "                outputs = outputs + output\n",
    "            outputs = outputs / len(models)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Decode predictions\n",
    "    pred_labels = encoder.inverse_transform(preds)\n",
    "\n",
    "if ENSEMBLE == 'hv':\n",
    "    models = []\n",
    "    for i in range(N_FOLDS):\n",
    "        model_state_dict = torch.load(f'./{TRIAL_NAME}_{i}_model_weight.pth',)\n",
    "        model = timm.create_model(\n",
    "            model_name=MODEL_NAME,\n",
    "            pretrained=False,\n",
    "            num_classes=CLASSES,\n",
    "            in_chans=1\n",
    "        ).to(device)\n",
    "        model.load_state_dict(model_state_dict)\n",
    "        models.append(model)\n",
    "\n",
    "    total_dataset = CustomDataset(pixel_df=train.iloc[: , 2:], label_df=train.iloc[: , 1], transform=test_transform)\n",
    "    total_loader = DataLoader(total_dataset, shuffle=True, **loader_params)\n",
    "\n",
    "    total_loss, total_acc = hv_validate_one_epoch(models, total_loader, criterion, device)\n",
    "    print(f\"HV model's Test Loss: {total_loss:.4f} | Test Accuracy: {total_acc*100:.4f}%\")\n",
    "\n",
    "\n",
    "    test_dataset = CustomDataset(pixel_df=test.iloc[:, 1:], transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=False, **test_loader_params)\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            sf_outputs = torch.zeros((images.size(0), CLASSES)).to(device)\n",
    "            outputs = torch.zeros((images.size(0), CLASSES)).to(device)\n",
    "            for model in models:\n",
    "                output = model(images)\n",
    "\n",
    "                if TTA:\n",
    "                    tta_images = [tta_transform(images) for tta_transform in tta_transforms]\n",
    "                    tta_outputs = [model(tta_image) for tta_image in tta_images]\n",
    "                    output = [output] + tta_outputs\n",
    "                    output = torch.stack(output).mean(dim=0)\n",
    "                \n",
    "                # soft-voting\n",
    "                sf_outputs = sf_outputs + output\n",
    "\n",
    "                # hard-voting\n",
    "                _, predict_indices = torch.max(output.data, dim=1)\n",
    "                pred_one_hot = torch.zeros((images.shape[0], CLASSES)).to(device)\n",
    "                pred_one_hot.scatter_(1, predict_indices.unsqueeze(1), 1)\n",
    "                outputs = outputs + pred_one_hot\n",
    "\n",
    "            max_val, _ = torch.max(outputs, dim=1, keepdim=True)\n",
    "            cnt = torch.sum(outputs == max_val, dim=1)\n",
    "            for i in range(cnt.shape[0]):\n",
    "                if cnt[i] > 1:\n",
    "                    output[i] = sf_outputs[i]\n",
    "            outputs = outputs / len(models)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Decode predictions\n",
    "    pred_labels = encoder.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission['label'] = pred_labels\n",
    "submission.to_csv(TRIAL_NAME + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
